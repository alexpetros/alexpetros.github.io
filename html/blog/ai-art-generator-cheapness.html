<!DOCTYPE html>
<html lang="en">
<meta charset="UTF-8">
<title>The Unbearable Cheapness of AI Art</title>
<link rel="stylesheet" href="/resources/stylesheets.css">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Twitter -->
<meta property="twitter:card" content="summary_large_image" />
<meta name="twitter:creator" content="@goodtweetsalex" />
<meta property="twitter:url" content="https://thefloatingcontinent.com/blog/ai-art-generator-cheapness" />
<meta property="twitter:title" content="The Unbearable Cheapness of AI-Generated Art" />
<meta property="twitter:description" content="On the difference between a newsletter and a magazine" />
<meta property="twitter:image" content="https://thefloatingcontinent.com/resources/blog/elon-musk-ai-image.png" />

<body class=blog>

<header class=basic>
<a href="/">^Home</a>
</header>

<article>
<h1>The Unbearable Cheapness of AI-Generated Art</h1>

<p>
As occasionally befalls internet culture writers, it was once again time for Charlie Warzel to write a piece about Alex Jones.

<p>
The top photo for articles about figures like Alex Jones tend to coagulate into a few familiar poses.
Yelling at the camera; yelling at the InfoWars desk; yelling on the street—you get the idea.
These quickly become repetitive, so Warzel used the Midjourney AI art generator to produce a different spin on the classic Jones image, and used it to introduce <a href="https://newsletters.theatlantic.com/galaxy-brain/62f28a6bbcbd490021af2db4/where-does-alex-jones-go-from-here/">his article about Alex Jones' day in court.</a>
This made a bunch of people angry, because it appeared to validate fears that machine learning models are about to replace illustrators in publications like <cite>The Atlantic</cite>, which purchased Warzel's newsletter last year.

<p>
This is a reasonable fear.
The technology that allows you to type a simple idea and have an algorithm conjure it into existence is miraculous.
If businesses—particularly the notoriously stingy media businesses—can cut costs and keep the same level of quality, they will definitely do so.
But I am skeptical that Midjourney is going to replace a lot of work for illustrators, precisely because it cannot produce that level of quality on its own.

<figure>
<img style="max-height:400px"
src="/resources/blog/alex-jones-ai-art-image.png"
alt="A Midjourney-generated image of InfoWars host Alex Jones sitting alone at a desk, surrounded by newspapers."/>
<figcaption>"Alex Jones inside an American Office under fluorescent lights" <br> (AI art by Midjourney, text prompt by Charlie Warzel)</figcaption>
</figure>

<p>
Consider the offending illustration of Alex Jones.
It is vivid, morose, admittedly striking, and <em>immediately</em> recognizable as a product of contemporary AI technology: the eyes are all messed up; one of his eyelids is a skin flap; newspapers bleed into each other and into the severed thing that looks like a hand; all the text is the weird glyph language that lives inside these image models.
While it doesn't look bad, really, it's not the kind of thing that would look good in the pages of <cite>The Atlantic</cite>.
As Warzel explained in <a href="https://newsletters.theatlantic.com/galaxy-brain/62fc502abcbd490021afea1e/twitter-viral-outrage-ai-art/">a follow-up blog</a>, his newsletter has access to a Getty account, but no budget for an illustrator.
It turns out that one of the things that distinguishes a newsletter from a magazine is money for art.

<p>
If you were being very generous, you could say that the Midjourney image of Alex Jones communicates something like "Alex Jones is slowly becoming the incoherent nonsense he's spent his life spreading."
But you can't do that, because you know it's a lie.
Even if the illustration were more convincing, the moment you identify it as a product of Midjourney, you feel differently about it.
The infinite space where meaning could have existed collapses into a single phrase: "Alex Jones inside an American Office under fluorescent lights."

<p>
I'm not (just) making a judgement about the quality of Midjourney, Stable Diffusion, DALL-E et.
al, or even a prediction about the likelihood that they will improve—I'm saying that a tool where you type a prompt and it creates an image is far too crude to produce art in all but vanishingly rare circumstances.
DALL-E 2 is a crayon.

<p>
To pick on another newsletter author I respect, Casey Newton from <em>Platformer</em> has been making occasional use of DALL-E 2 to decorate his articles.
In <a href="https://www.platformer.news/p/elon-keeps-losing">a recent post about Elon Musk's Twitter lawsuit,</a> Casey leads with an image generated by DALL-E that shows a Tesla driving off a cliff.
Look at the difference between Casey's DALL-E image and the header image from <a href="https://www.theverge.com/2022/9/7/23339673/musk-twitter-trial-delay-request-denied-whistleblower-claims-granted">a <cite>Verge</cite> article he links to</a>, about the exact same subject.

<figure style="whitespace: nowrap;">
<div>
<img style="max-height:300px; margin-right: 20px;"
src="/resources/blog/musk-images-side-by-side.png"
alt="A comparison between two images. The image on the left is a faux-realstic depicition of a Tesla driving off a cliff. The image on the right is digital art of an image of Elon Musk superimposed over a wallpaper-like patterned background of old-fashinged scales."/>
</div>
<figcaption style="">"Tesla driving off a cliff" (AI art by DALL-E 2, prompt by Casey Newton, left) next to the header image for "Judge denies Elon Musk's attempt to delay Twitter trial" on <cite>The Verge</cite> (Kristen Radtke, right) </figcaption>

</figure>

<p>
Especially in context, it's so obvious which of these was produced by a professional media company and which was whipped out by a machine learning model on the basis of a sentence fragment.
The Tesla image is kind of funny, but it's mostly meant to fill space at the top of the article.
Compare that with the image from <cite>The Verge</cite> (by Associate Creative Director Kristen Radtke), which is simple, effective, consistent with <em>The Verge</em>'s visual identity, and instantly communicates what the article is about.
A machine can't do that based on a sentence; an artist can.

<p>
And believe me, I asked:

<figure>
<img style="max-height:400px"
src="/resources/blog/elon-musk-ai-image.png"
alt="Four very low-quality AI-generated images of what sort of looks like Elon Musk."/>
<figcaption>"header image for an article about Elon Musk's lawsuit written by the verge" <br> (AI art by Midjourney, text prompt by Alex Petros)</figcaption>
</figure>

<p>
Our relationship with computers is already suffused with artificial intelligence, arguably nowhere more so than in visual art.
Every digital camera—from an iPhone 11 to a Nikon Z 9—makes millions of tiny decisions about what it thinks the photo should look like when you shoot in program mode, and it makes almost as many decisions <em>in manual mode</em>.
This definitely makes digital photography look different from film photography, but it has a surprisingly small effect on the qualities that make make a great photo; program mode mostly helps more people take photos that are good enough.
AI gives us a lot more levers to pull, but talent and skill are still required to operate them.

<p>
Did you read the story about Jason Allen, the guy who won a blue ribbon at the Colorado State Fair arts competition with AI-generated art?

<figure>
<img style="max-height:400px"
src="/resources/blog/jason-allen-ai-art.jpg"
alt="A digital art image of three foreground characters looking towards a giant open window, with what appears to be an audience in between them. The colors are primarily gold, brown, and red."/>
<figcaption>"Théâtre D’opéra Spatial" (Jason Allen, via <cite>The Washington Post</cite>)</figcaption>
</figure>

Here's what he did to produce the winning images, <a href="https://www.washingtonpost.com/technology/2022/09/02/midjourney-artificial-intelligence-state-fair-colorado/">as described by <cite>The Washington Post</cite></a>:

<p>
<blockquote>
<p>
He started with a simple mental image — "a woman in a Victorian frilly dress, wearing a space helmet" — and kept fine-tuning the prompts, "using tests to really make an epic scene, like out of a dream."
He said he spent 80 hours making more than 900 iterations of the art, adding words like "opulent" and "lavish" to fine tune its tone and feel. [...]
<p>
When he found images he really liked, he pulled them into Adobe Photoshop to remove visual artifacts.
In one image, the central figure was missing a head, so he also painted in a crop of dark, wavy hair.
He used another machine-learning tool, <a href="https://www.topazlabs.com/gigapixel-ai">Gigapixel AI</a>, to increase the photos’ quality and sharpness, then printed the three pieces on canvas — all variations on the French phrase for “space opera theater,” which he thought sounded cool — and drove to submit them to the state fair.
</blockquote>

<p>
That's... a lot of work!
Allen used Midjourney for inspiration and at least three tools total to produce the image he saw in his mind's eye.
One of tools he used, Adobe Photoshop, has been a mainstay of digital art for decades.
Photoshop uses mountains of machine learning to figure out what you're trying to do.
To my knowledge, this is not particularly controversial within the digital art community, presumably because the AI-enabled tools inside Photoshop require effort and skill to produce a convincing image.

<p>
And to be honest, the result is cool, but it's cool in the way my desktop backgrounds were cool after I convinced my mom that having two 14-inch monitors was absolutely essential for completing my middle-school homework productively.
It's exactly the kind of thing a highly-motivated novice should be able to enter in a fair whose primary purpose is recognizing the best cow.

<figure>
<img style="max-height:400px"
src="/resources/blog/alex-with-the-winning-cows.jpg"
alt="A man in a sweatshirt and shorts giving the camera a thumbs-up while standing in front of two white cows that are facing away from him. The cows have ribbons on their enclosure indiciating their status as state fair champions."/>
<figcaption>The author with some of this year's best cows at the Wisconsin State Fair</figcaption>
</figure>

<p>
Art can only resonate with you precisely as much as you consider it, and the longer you spend considering any work of AI-generated art, the more the illusion shatters.
Who made this?
Why did they make it?
What impact did it have?
Art created by humans has answers to these questions, which is why museums have placards: the more you learn, the more likely it will mean something to you.
The AI art generators might get better, but the stories never will.

<p>
It's important that we develop some social antibodies to the use of this technology.
It remains crucial to credit artists, and in the process make it clear what was made by artists and what was made by machines.
We need a technical and legal regime that makes it possible for artists to protect their work and prevent its appropriation to train these models.
Some communities—<a href="https://www.vice.com/en/article/y3pb8g/furry-fandom-site-fur-affinity-banned-ai-art">like our digital Cassandras, the furries</a>—have opted to ban them.
I think that's good and reasonable.
We should continue to demand artistic quality from our media companies, magazines, and creative enterprises, which necessarily requires that they employ artists.

<p>
But if you're writing a newsletter?
It just looks cheap, and it cheapens your writing to include it.
You might want to stick to Getty.

<p class=postscript>
Thanks to Spencer Hamersmith for his feedback on an draft of this post.

<h2>Addendum to show I'm not a hater</h2>
<p>
Consider this Twitter thread, in which Twitter user @images_ai "fixes" famous paintings with AI:

<p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">You might recognize A Sunday Afternoon on the Island of La Grande Jatte by Seurat, but you&#39;d be forgiven for not understanding the scene right away. If you look close, the painting is made of many tiny dots, which can make it hard to see what&#39;s going on. That&#39;s an easy fix!<br><br>/ <a href="https://t.co/gAZTKXaa0x">pic.twitter.com/gAZTKXaa0x</a></p>&mdash; images_ai (@images_ai) <a href="https://twitter.com/images_ai/status/1566895787770093568?ref_src=twsrc%5Etfw">September 5, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>
I think this is hysterical.
I love the deadpan description of pointillism (which can make it hard to see what's going on!), the absurd idea that impressionism is something to be fixed, and the fact that the computer replaced a canoe with a pickup trick and turned the river into a sort of wet parking lot.
It made me smile, it made me think, and I scrolled away from it with an ever-so-slightly different idea about what it means to exist in the world at this particular moment.

<p>
Artificial intelligence can wielded to produce art, but what makes it art has little to do with the machine and everything to do with the skill and humanity of the artist who wields it.

</article>
